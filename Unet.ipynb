{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVgciRa5r2ysbh7NfnnMYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-nait/Heart-Failure-Symptomes-detection/blob/master/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zV4TimLclYC"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mehdi-nait/Heart-Failure-Symptomes-detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "!pip install wandb\n",
        "import wandb"
      ],
      "metadata": {
        "id": "lMozfDdcp4ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Fb4vCGU8Slsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "pcIu_g1jxWUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_seg(Dataset):\n",
        "  \"\"\"Creates dataset object given image and labels directory\n",
        "  \n",
        "  Inputs:\n",
        "  -------------------\n",
        "  image_dir : images directory\n",
        "  label_dir : labels directory\n",
        "  transform : transformations to be applied to the labels and images\n",
        "\n",
        "  Returns : \n",
        "  -------------------\n",
        "  Dataset object  \n",
        "  \"\"\"\n",
        "    \n",
        "    def __init__(self,image_dir,label_dir,transform = None):\n",
        "        \n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.images = [image_dir+x for x in self.images]\n",
        "        \n",
        "        self.labels = os.listdir(label_dir)\n",
        "        self.labels = [label_dir+x for x in self.labels]\n",
        "        self.transform = transform\n",
        "        self.size_img = (256,256)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        image = cv2.imread(self.images[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        label = cv2.imread(self.labels[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        image = cv2.resize(image,self.size_img)\n",
        "        label = cv2.resize(label,self.size_img)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            label = self.transform(label)\n",
        "        \n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        return image,label\n",
        "        \n",
        "        "
      ],
      "metadata": {
        "id": "Pd9BnFVwpw3D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    \n",
        "    super(Block,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3)\n",
        "    self.relu  = nn.ReLU()\n",
        "    self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.batch_norm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "m6wB_orLqBRM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self,channels = (1,16,32,64)):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    self.encode_blocks = nn.ModuleList(Block(channels[i],channels[i+1]) for i in range(len(channels)-1))\n",
        "    self.pooling = nn.MaxPool2d(2,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    for block in self.encode_blocks:\n",
        "\n",
        "      x = block(x)\n",
        "      outputs.append(x)\n",
        "      x = self.pooling(x)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "3nj2erzprBri"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self,channels = (64,32,16)):\n",
        "\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.channels = channels\n",
        "    self.up_convs  = nn.ModuleList(nn.ConvTranspose2d(channels[i],channels[i+1],2,2) for i in range(len(channels)-1))\n",
        "    self.dec_blocks = nn.ModuleList(Block(channels[i],channels[i+1]) for i in range(len(channels)-1))\n",
        "    self.batch_norms = nn.ModuleList(nn.BatchNorm2d(channels[i+1]) for i in range(len(channels)-1))\n",
        "\n",
        "  def forward(self,x,enc_features):\n",
        "\n",
        "    for i in range(len(self.channels)-1):\n",
        "      \n",
        "      x = self.up_convs[i](x)\n",
        "      x = self.batch_norms[i](x)\n",
        "      enc_feature = self.copy_crop(enc_features[i],x)\n",
        "      x = torch.cat((enc_feature,x),dim=1)\n",
        "      x = self.dec_blocks[i](x)\n",
        "\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "  def copy_crop(self,feature,x):\n",
        "\n",
        "    _,_,H,W = x.shape\n",
        "    cropped_feature = transforms.CenterCrop([H,W])(feature)\n",
        "    return cropped_feature"
      ],
      "metadata": {
        "id": "PtDJ1aVbtd2H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "\n",
        "  def __init__(self, enc_channels = (1,64,128,256,512), dec_channels = (512,256,128,64),nb_classes = 1, retainDim = True, out_size=(256,256)):\n",
        "    super(Unet,self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(enc_channels)\n",
        "    self.decoder = Decoder(dec_channels)\n",
        "    \n",
        "    self.head = nn.Conv2d(dec_channels[-1], nb_classes, 1)\n",
        "    self.retainDim = retainDim\n",
        "    self.outSize = out_size\n",
        "    \n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "    enc_features = self.encoder(x)\n",
        "\n",
        "    dec_features = self.decoder(enc_features[::-1][0],enc_features[::-1][1:])\n",
        "\t\t\n",
        "    map = self.head(dec_features)\n",
        "\n",
        "    if self.retainDim:\n",
        "      map = F.interpolate(map, self.outSize)\n",
        "    \n",
        "  \n",
        "    return map"
      ],
      "metadata": {
        "id": "0Ov8KVY1rta4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        smooth = 1\n",
        "        num = targets.size(0)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        intersection = (m1 * m2)\n",
        "\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
        "        score = 1 - score.sum() / num\n",
        "        return score"
      ],
      "metadata": {
        "id": "HNagCtZnclkU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCE_DiceLoss(nn.Module):\n",
        "  def __init__(self,weight = None,size_average = True):\n",
        "    super(BCE_DiceLoss,self).__init__()\n",
        "    \n",
        "  def forward(self,logits,targets):\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "    dice_loss = SoftDiceLoss()\n",
        "    return bce(logits, targets) + dice_loss(logits, targets)"
      ],
      "metadata": {
        "id": "cQf4tNI-baRm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(train_dir,valid_dir,BATCH_SIZE = 10):\n",
        "\n",
        "  train_dataset = Dataset_seg(train_dir+\"/Images/\",train_dir+\"/Labels/\",transforms.ToTensor())\n",
        "  valid_dataset = Dataset_seg(valid_dir+\"/Images/\",valid_dir+\"/Labels/\",transforms.ToTensor())\n",
        "\n",
        "  valid_dataloader = DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "  trainSteps = len(train_dataset) // BATCH_SIZE\n",
        "  testSteps = len(valid_dataset) // BATCH_SIZE\n",
        "\n",
        "  return train_dataloader,valid_dataloader,trainSteps,testSteps"
      ],
      "metadata": {
        "id": "HLrJSv50YDXV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"Data/Dataset/Train/\"\n",
        "valid_dir = \"Data/Dataset/Test/\"\n",
        "BATCH_SIZE = 10\n",
        "train_loader,valid_loader,train_steps,test_steps = create_dataset(train_dir,valid_dir,BATCH_SIZE)"
      ],
      "metadata": {
        "id": "9plVzObYYurf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Unet()\n",
        "loss_function = BCE_DiceLoss()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.99)\n",
        "\n",
        "# initialize a dictionary to store training history\n",
        "H = {\"train_loss\": [], \"test_loss\": []}"
      ],
      "metadata": {
        "id": "bnL-bEl13kgm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config = {\n",
        "  \"Loss_function\" : \"BCE_DiceLoss\",\n",
        "  \"Optimizer\" : \"SGD W/ Momentum\",\n",
        "  \"Image_Size\" : 256,\n",
        "  \"U-net layers\":(1,64,128,256,512,1024),\n",
        "  \"Learning_rate\": 0.0002,\n",
        "  \"Epochs\": 100,\n",
        "  \"Batch_size\": 10,\n",
        "  \"Device\" : \"GPU\"\n",
        "}\n",
        "\n",
        "\n",
        "wandb.init(config=wandb.config,project=\"LV-Seg\", entity=\"mehdi-nait\")\n"
      ],
      "metadata": {
        "id": "OgJaCFLya55x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = wandb.config[\"Epochs\"]\n",
        "\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n",
        "model = model.cuda()\n",
        "for e in tqdm(range(NUM_EPOCHS)):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  totalTrainLoss = 0\n",
        "  totalTestLoss = 0\n",
        "\n",
        "  for (i, (x, y)) in enumerate(train_loader):\n",
        "    \n",
        "    (x, y) = (x.cuda(), y.cuda())\n",
        "    pred = model(x)\n",
        "  \n",
        "    loss = loss_function(pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    totalTrainLoss += loss\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for (x, y) in valid_loader:\n",
        "        \n",
        "        pred = model(x)\n",
        "        totalTestLoss += loss_function(pred, y)\n",
        "  \n",
        "  avgTrainLoss = totalTrainLoss / train_steps\n",
        "  avgTestLoss = totalTestLoss / test_steps\n",
        "\n",
        "  H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "  H[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
        "\n",
        "  wandb.log({\n",
        "        \"Train Loss\": avgTrainLoss,\n",
        "        \"Valid Loss\": avgTestLoss})\n",
        "\n",
        "  print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
        "  print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n",
        "\n",
        "endTime = time.time()\n",
        "\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
      ],
      "metadata": {
        "id": "_bbKarVl4aDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model saving\n",
        "\n",
        "EPOCH = 100\n",
        "PATH = \"Unet_1024.pt\"\n",
        "LOSS = 0.001\n",
        "\n",
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': LOSS,\n",
        "            }, PATH)"
      ],
      "metadata": {
        "id": "A2ISAUt2MZC6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "k76fSNnH4WJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"Unet_1024.pt\"\n",
        "\n",
        "model = Unet()\n",
        "model = model.to(device)\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAkPZ75PMIrc",
        "outputId": "a591e96b-a70a-4b52-fcc5-49fa4c13ea91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = Dataset_seg(valid_dir+\"/Images/\",valid_dir+\"/Labels/\",transforms.ToTensor())\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "URD_XZvHiIiL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,label = next(iter(valid_dataloader))\n",
        "\n",
        "y = model.forward(img)\n",
        "\n",
        "plt.imshow(img.cpu().squeeze())\n",
        "plt.show()\n",
        "\n",
        "output = y.cpu().detach().numpy().squeeze()\n",
        "plt.imshow(output)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(label.cpu().squeeze())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R_LE0tvhNCx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}